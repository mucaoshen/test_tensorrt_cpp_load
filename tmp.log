[09/12/2023-14:51:05] [TRT] [I] [MemUsageChange] Init CUDA: CPU +176, GPU +0, now: CPU 251, GPU 368 (MiB)
[09/12/2023-14:51:12] [TRT] [I] [MemUsageChange] Init builder kernel library: CPU +339, GPU +74, now: CPU 665, GPU 442 (MiB)
[09/12/2023-14:51:12] [TRT] [W] CUDA lazy loading is not enabled. Enabling it can significantly reduce device memory usage and speed up TensorRT initialization. See "Lazy Loading" section of CUDA documentation https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#lazy-loading
[09/12/2023-14:51:12] [TRT] [I] ----------------------------------------------------------------
[09/12/2023-14:51:12] [TRT] [I] Input filename:   ResNet34_trackerOCR_36_450_20230627_half.onnx
[09/12/2023-14:51:12] [TRT] [I] ONNX IR version:  0.0.8
[09/12/2023-14:51:12] [TRT] [I] Opset version:    16
[09/12/2023-14:51:12] [TRT] [I] Producer name:    pytorch
[09/12/2023-14:51:12] [TRT] [I] Producer version: 1.13.1
[09/12/2023-14:51:12] [TRT] [I] Domain:           
[09/12/2023-14:51:12] [TRT] [I] Model version:    0
[09/12/2023-14:51:12] [TRT] [I] Doc string:       
[09/12/2023-14:51:12] [TRT] [I] ----------------------------------------------------------------
[09/12/2023-14:51:12] [TRT] [W] onnx2trt_utils.cpp:374: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.
[09/12/2023-14:51:12] [TRT] [I] BuilderFlag::kTF32 is set but hardware does not support TF32. Disabling TF32.
[09/12/2023-14:51:13] [TRT] [I] Graph optimization time: 0.197741 seconds.
[09/12/2023-14:51:13] [TRT] [I] BuilderFlag::kTF32 is set but hardware does not support TF32. Disabling TF32.
[09/12/2023-14:51:13] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.
[09/12/2023-14:51:39] [TRT] [I] Detected 1 inputs and 1 output network tensors.
[09/12/2023-14:51:39] [TRT] [I] Total Host Persistent Memory: 151920
[09/12/2023-14:51:39] [TRT] [I] Total Device Persistent Memory: 244736
[09/12/2023-14:51:39] [TRT] [I] Total Scratch Memory: 31661568
[09/12/2023-14:51:39] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 121 MiB, GPU 174 MiB
[09/12/2023-14:51:39] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 35 steps to complete.
[09/12/2023-14:51:39] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 0.284769ms to assign 3 blocks to 35 nodes requiring 39955968 bytes.
[09/12/2023-14:51:39] [TRT] [I] Total Activation Memory: 39955968
[09/12/2023-14:51:39] [TRT] [W] TensorRT encountered issues when converting weights between types and that could affect accuracy.
[09/12/2023-14:51:39] [TRT] [W] If this is not the desired behavior, please modify the weights or retrain with regularization to adjust the magnitude of the weights.
[09/12/2023-14:51:39] [TRT] [W] Check verbose logs for the list of affected weights.
[09/12/2023-14:51:39] [TRT] [W] - 7 weights are affected by this issue: Detected subnormal FP16 values.
[09/12/2023-14:51:39] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +0, GPU +46, now: CPU 0, GPU 46 (MiB)
[09/12/2023-14:51:40] [TRT] [I] Loaded engine size: 47 MiB
[09/12/2023-14:51:40] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +46, now: CPU 0, GPU 46 (MiB)
[09/12/2023-14:51:40] [TRT] [I] [MS] Running engine with multi stream info
[09/12/2023-14:51:40] [TRT] [I] [MS] Number of aux streams is 1
[09/12/2023-14:51:40] [TRT] [I] [MS] Number of total worker streams is 2
[09/12/2023-14:51:40] [TRT] [I] [MS] The main stream provided by execute/enqueue calls is the first worker stream
[09/12/2023-14:51:40] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +38, now: CPU 0, GPU 84 (MiB)
[09/12/2023-14:51:40] [TRT] [W] CUDA lazy loading is not enabled. Enabling it can significantly reduce device memory usage and speed up TensorRT initialization. See "Lazy Loading" section of CUDA documentation https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#lazy-loading
demo_trt.py:79: DeprecationWarning: Use build_serialized_network instead.
  with builder.build_engine(network, config) as engine, open(f, 'wb') as t:
demo_trt.py:106: DeprecationWarning: Use get_tensor_name instead.
  name = model.get_binding_name(i)
demo_trt.py:107: DeprecationWarning: Use get_tensor_dtype instead.
  dtype = trt.nptype(model.get_binding_dtype(i))
demo_trt.py:109: DeprecationWarning: Use get_tensor_mode instead.
  if model.binding_is_input(i):
demo_trt.py:110: DeprecationWarning: Use get_tensor_shape instead.
  if -1 in tuple(model.get_binding_shape(i)):
demo_trt.py:112: DeprecationWarning: Use get_tensor_profile_shape instead.
  context.set_binding_shape(i, tuple(model.get_profile_shape(0, i)[2]))
demo_trt.py:112: DeprecationWarning: Use set_input_shape instead.
  context.set_binding_shape(i, tuple(model.get_profile_shape(0, i)[2]))
demo_trt.py:120: DeprecationWarning: Use get_tensor_shape instead.
  shape = tuple(context.get_binding_shape(i))
trt version:  8.6.1
TensorRT input 'images' with shape(-1, 1, 36, 450) DataType.HALF
TensorRT input 'output0' with shape(-1, 57, 14665) DataType.HALF
Traceback (most recent call last):
  File "demo_trt.py", line 148, in <module>
    model = get_engine(f)
  File "demo_trt.py", line 127, in get_engine
    if isinstance(metadata, (str, Path)) and Path(metadata).exists():
UnboundLocalError: local variable 'metadata' referenced before assignment
